{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADEME VRP\n",
    "\n",
    "Pour résoudre la problématique du projet ADEME la contrainte sélectionnée est celle des k camions, nous retrouverons le code pour notre solution ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_cities = 1500 # Number of cities\n",
    "cities = np.random.randint(1, 101, size=(n_cities, n_cities)) # Initizaliting adjcency matrix with weight from 1 to 100 and n cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m best_paths, best_total_length \u001b[39m# Return the best paths and the total length of the best paths\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m# adjust the parameters to get the best result (add ants/iterations for precision (but slower) and increase alpha/beta for exploration)\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m best_paths, best_total_length \u001b[39m=\u001b[39m ant_colony_optimization_vrp(cities, n_ants\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, n_iterations\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, beta\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, evaporation_rate\u001b[39m=\u001b[39;49m\u001b[39m0.4\u001b[39;49m, Q\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m, n_trucks\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m     85\u001b[0m \u001b[39m# showing the best path and distance for each truck\u001b[39;00m\n\u001b[0;32m     86\u001b[0m total_dist \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[69], line 55\u001b[0m, in \u001b[0;36mant_colony_optimization_vrp\u001b[1;34m(cities, n_ants, n_iterations, alpha, beta, evaporation_rate, Q, n_trucks)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     probabilities \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(probabilities) \u001b[39m# normalizing the probabilities\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m next_point \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(unvisited, p\u001b[39m=\u001b[39;49mprobabilities) \u001b[39m# choosing the next city based on the probabilities\u001b[39;00m\n\u001b[0;32m     56\u001b[0m path\u001b[39m.\u001b[39mappend(next_point)\n\u001b[0;32m     57\u001b[0m path_length \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cities[current_point][next_point]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ant_colony_optimization_vrp(cities, n_ants, n_iterations, alpha, beta, evaporation_rate, Q, n_trucks):\n",
    "    '''\n",
    "    ACO for Vehicle Routing Problem.\n",
    "    Parameters:\n",
    "        cities: 2D array of distances between cities (adjacency matrix)\n",
    "        n_ants: Number of ants running per iteration\n",
    "        n_iterations: Number of iterations\n",
    "        alpha: Importance of pheromone\n",
    "        beta: Importance of distance\n",
    "        evaporation_rate: Rate at which pheromone evaporates\n",
    "        Q: Constant for pheromone update / Amount of pheromones ants release\n",
    "        n_trucks: Number of trucks available\n",
    "    Returns:\n",
    "        best_paths: List of best paths found by the algorithm\n",
    "        best_total_length: Total length of the best paths\n",
    "\n",
    "    adapted the source code for our purpose (no coordinate/matplotlib in our version and added truck constraint)\n",
    "    source: https://induraj2020.medium.com/implementation-of-ant-colony-optimization-using-python-solve-traveling-salesman-problem-9c14d3114475\n",
    "\n",
    "    '''\n",
    "    pheromone = np.ones((n_cities, n_cities)) # Initizaliting pheromone matrix with 1s\n",
    "    best_paths = None \n",
    "    best_total_length = np.inf\n",
    "    max_cities_per_truck = n_cities // n_trucks  # Maximum cities each truck can visit\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        all_paths = []\n",
    "        all_total_lengths = []\n",
    "\n",
    "        for ant in range(n_ants):\n",
    "            paths = []\n",
    "            total_length = 0\n",
    "            visited_global = np.zeros(n_cities, dtype=bool)  # Global visited array for all trucks in this iteration (filled with False)\n",
    "\n",
    "            for truck in range(n_trucks):\n",
    "                visited = visited_global.copy()  # Using the global visited array for each truck\n",
    "                current_point = 0  # Start from the depot\n",
    "                # start from depot and visit max_cities_per_truck cities\n",
    "                visited[current_point] = True \n",
    "                path = [current_point]\n",
    "                path_length = 0\n",
    "                cities_visited = 0  # Count of visited cities\n",
    "\n",
    "                # Loop through not visited cities\n",
    "                while np.any(np.logical_not(visited)) and cities_visited < max_cities_per_truck :\n",
    "                    unvisited = np.where(np.logical_not(visited))[0] # getting the next unvisited cities\n",
    "                    # calculating the probabilities of the next cities\n",
    "                    probabilities = pheromone[current_point][unvisited]**alpha * (1/cities[current_point][unvisited])**beta\n",
    "                    # if all the probabilities are 0, set them to 1/len(probabilities) to avoid division by 0\n",
    "                    if np.sum(probabilities) == 0:\n",
    "                        probabilities = np.ones_like(probabilities) / len(probabilities)\n",
    "                    else:\n",
    "                        probabilities /= np.sum(probabilities) # normalizing the probabilities\n",
    "\n",
    "                    next_point = np.random.choice(unvisited, p=probabilities) # choosing the next city based on the probabilities\n",
    "                    path.append(next_point)\n",
    "                    path_length += cities[current_point][next_point]\n",
    "                    visited[next_point] = True\n",
    "                    visited_global[next_point] = True  # Mark city as visited in the global array\n",
    "                    current_point = next_point\n",
    "                    cities_visited += 1  # Increase the count of visited cities\n",
    "\n",
    "                path_length += cities[path[-1]][0] # adding the distance from the last city to the depot\n",
    "                path.append(0) # adding the depot to the path to complete the cycle\n",
    "                paths.append(path)\n",
    "                total_length += path_length\n",
    "\n",
    "            all_paths.append(paths)\n",
    "            all_total_lengths.append(total_length)\n",
    "\n",
    "            if total_length < best_total_length:\n",
    "                best_paths = paths\n",
    "                best_total_length = total_length\n",
    "\n",
    "        pheromone *= evaporation_rate # Evaporate pheromone\n",
    "\n",
    "        for paths, total_length in zip(all_paths, all_total_lengths):\n",
    "            for path in paths:\n",
    "                pheromone[path[:-1], path[1:]] += Q / total_length # Update pheromone\n",
    "                pheromone[path[-1], path[0]] += Q / total_length # Update pheromone\n",
    "\n",
    "    return best_paths, best_total_length # Return the best paths and the total length of the best paths\n",
    "# adjust the parameters to get the best result (add ants/iterations for precision (but slower) and increase alpha/beta for exploration)\n",
    "best_paths, best_total_length = ant_colony_optimization_vrp(cities, n_ants=10, n_iterations=40, alpha=2, beta=2, evaporation_rate=0.4, Q=70, n_trucks=3)\n",
    "# showing the best path and distance for each truck\n",
    "total_dist = 0\n",
    "for i, path in enumerate(best_paths): # Loop through the best paths\n",
    "    path_distance = 0\n",
    "    for j in range(len(path) - 1):\n",
    "        distance = cities[path[j]][path[j+1]]\n",
    "        path_distance += distance\n",
    "        total_dist+= distance\n",
    "    print(f\"Truck {i+1}: {path} {path_distance}km\")\n",
    "print(f\"total distance: {total_dist}km\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db976db827db0eae9b5d6f36130ee2a58388d42ffc430dde9b54af37dbc4c738"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
